---
title: "DEVOIR_S2 DATA_MINING"
author: "SABAYE Fried-Junior, Caleb KASHALA, Mohamad EL KAWASS, Hicham AZOUD"
header-includes:
- \usepackage[Glenn]{fncychap}
- \usepackage{fancyhdr}
fontsize: 12pt
lang: 'fr'
geometry: a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm
output: 
   pdf_document :
       toc : yes 
       number_section : yes
       highlight: "tango"

---
```{r, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE,fig.pos = "!h", sanitize=TRUE, fig.align='center',strip.white = TRUE)
```



```{r}
library(ISLR)
library(missMDA)
library(MASS)
library(ROCR)
library(dplyr)# en particulier pour la syntae %>%
library(rsample)
library(class)# package contenant la focntion knn
library(rpart) # package pour les arbres CART
library(rpart.plot)
library(randomForest)
library(e1071)
library(tidyr)
library(ggplot2)
library(parallel)
library(doParallel)
library(caret)
library(parallel)
library(FactoMineR)
library(mice)
library(plotROC)
library(ROCR)
library(ada)
library(precrec)
library(gridExtra)
library(formattable)
library(stargazer)
library(kableExtra)
set.seed(124)
```



# Initilaisation des données

Après la transformation, la sélection des variables et l'affectation des effectifs réalisée $\textbf{au premier semestre}$, les variables restantes pouvant être utilisées  sont : *Bike_Age,  Bike_Alc_D, Bike_Dir, Bike_Injur, Bike_Pos, Bike_Race, Bike_Sex, Crash_Hour, Crash_Loc, Crash_Time, Crash_Type, Crash_Ty_1, Developmen, DrvrAge_Gr, Drvr_Age, Drvr_Alc_D, Drvr_Injur, Drvr_Race, Drvr_Sex, Hit_Run, Light_Cond, Num_Lanes, Num_Units,  Rd_Charact, Rd_Class, Rd_Conditi, Region, Rural_Urba et Workzone_I.*

Cependant d'autres transformations seront peut-être nécessaires.

```{r}
data<-read.table("bike_crash.csv", header = T, sep = ";")
newdataqual<-data[,-c(1,2,3,4,12,13,14,15,16,17,18,19,20,21,22,23,24,25,27,28,30,34,38,39,40,41,44,45,46,47,50,51,54)]
newdataqual$Bike_Injur<-as.character(newdataqual$Bike_Injur)
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="A: Disabling Injury"]<-"Oui"
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="B: Evident Injury"]<-"Oui"
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="C: Possible Injury"]<-"Non"
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="Injury"]<-"Oui"
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="K: Killed"]<-"Oui"
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="O: No Injury"]<-"Non"
df<-newdataqual[complete.cases(newdataqual), ]
```

## Affectation 

On effectue un tirage aléatoire sans remise. 

La base de données sera séparée comme suit :  2/3 des accidents seront utilisés pour construire les modèles et les 1/3 restant seront utilisés pour tester nos modèles.

```{r}
data_split <- df %>% initial_split(prop = 2/3)
test_data <- data_split %>% testing()
train_data <- data_split %>% training()
df2<-train_data
```


## Variable à prédire

La variable que nous voulons prédire est Bike_Injur. Nous allons construire plusieurs modèles en ce sens et les comparer.  Puis  nous essaierons de déterminer le meilleur d'entre eux.

Après la transformation des modalités initiales on obtient :

```{r}
d<-data.frame(table(newdataqual$Bike_Injur))
colnames(d)<-c("Bike_Injur","Nombre")

kable(d,align = "c",caption="Effectif de la variable à prédire") %>%
kable_styling(latex_options =c("striped","hold_position"),full_width = F) 
```

# Arbres

Nous allons commencer par réaliser un modèle "arbre complet" sur toute la  base de donnée pour avoir une vue d'ensemble sur nos varibales. Ensuite nous allons essayer de l'affiner au fur et à mesure, en avançant dans notre étude.

## Arbre complet

```{r}
set.seed(124)

control.max <- rpart.control(cp = 0, max.depth = 0, minbucket = 1, minsplit = 1,xval = 10)
tree <- rpart(Bike_Injur~. , data = df2, control = control.max, parms = list(split = "information"))

```


```{r}
plot(tree,main="Arbre complet" ,col="red")

```

```{r}
plotcp(tree)
```

```{r}
cp=tree$cptable[which.min(tree$cptable[,4]),1]

```


Nous avons réalisé un graphique qui nous montre le taux erreur en fonction de la complexité. A l'aide de  ce graphique nous pouvons conclure que  la complexité qui permet à minimiser l'erreur estimée est de CP=$0.001420455$ avec une erreur relative égale à $0.88$.


## Arbre élagué 

```{r}
set.seed(124)
tree_pruned <- prune(tree, cp =cp )
prp(tree_pruned,col="red")
```

\

Cet arbre nous donne une idée générale de la classification de nos variables.


## Complet vs Élagué


```{r}
pred_tree<- predict(tree,
                 df2[,-4], type='prob')
pred_prune <- predict(tree_pruned,
                 df2[,-4], type='prob')

plot(pred_prune)
```


```{r}
predi_tree<- prediction(pred_tree[,1], (pull(df2, Bike_Injur)=="Non"))
perf_tree <- performance(predi_tree, measure = "tpr", x.measure = "fpr")
predi_prune <- prediction(pred_prune[,1], (pull(df2, Bike_Injur)=="Non"))
perf_prune <- performance(predi_prune, measure = "tpr", x.measure = "fpr")
```

Ici le graphique nous montre la VPP ( La valeur prédictive positive) qui est la probabilité que la condition "le cycliste ne soit pas bléssé" soit accepté lorsque le test est positif. Pour l'arbre complet on peut voir que cette valeur est proche de 1 et ceci s'explique par le fait que dans un arbre complet il y'a du surrapprentissage contrairement à un arbre simplifié.


```{r}
performance(predi_tree, measure = "acc") %>% plot(col="green",main="arbre complet")
performance(predi_prune, measure = "acc") %>% plot(col="green",main="arbre élagué")

```

 On a un taux de VPP pour l'arbre complet très élevé ce qui paraît un bon signe en premier lieu, mais ça pourrait être dû au surapprentissage du modéle sur nos données. Le fait d'avoir un arbre trop complet cause cette surrapprentissage et donc emmenéra a des mauvaises prédictions sur des données non connues.



## Courbe ROC:


```{r}
par(mfrow=c(1,2))
data.frame(pred_model1 = pred_prune[,1], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+ggtitle("Courbe ROC de l'arbre élagué") 

data.frame(pred_model1 = pred_tree[,1], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+ggtitle("Courbe ROC de l'arbre complet")

```

Comme prévu, la courbe de ROC de l'arbre complet est parfaite à cause du surrapprentissage. En revanche, la courbe de ROC de l'arbre simplifié, n'est pas aussi bonne, elle est près de la bissectrice et ce n'est pas un bon indice pour la prédiction du modèle.

## Mesure de performance

```{r}

performance(predi_prune, measure = "tpr") %>% plot(col="red",main="Grahique du taux de vrai positive et des vrai negative")
performance(predi_prune, measure = "tnr") %>% plot(col="blue", add = TRUE)
```


```{r}
performance(predi_prune, measure = "prec") %>% plot(col="red")
```
Ici on peut on peut également observer notre Courbe ROC pour les deux modéles, on s'aperçoit, comme nous l'avons évoqué précédemment, qu'il y'a du surrapprentissage sur l'arbre complet. Concernant l'arbre simplifié on note un changement de la pente fpf égale à $0.35$.

Les graphiques précédents permettent de constater qu'à un certain seuil  : 0.59, la perfermance de l'arbre élagué augmente nettement.

```{r}
library(precrec)
evalmod(scores = pred_prune[,1], labels = (pull(df2, Bike_Injur)=="Non"), mode="basic") %>%
  autoplot(c("error", "accuracy", "specificity", "sensitivity", "precision", "fscore"))
```

Les différents indicateurs indiquent qu'on a un modèle plutôt correct.



# Bagging et Random forest


```{r}
set.seed(124)
df2$Bike_Injur<-as.factor(df2$Bike_Injur)
rf <- randomForest(Bike_Injur~., data = df2, method = "class",
                   parms = list(split = "gini"), na.action = na.roughfix,
                   keep.forest = TRUE, importance = TRUE)


varImpPlot(rf, main = "Random Forest", cex = 0.8)

```

En faisant un random forest on obtient une erreur OOB ( Out Of Bagg ) égale à 44.47%.




```{r}
set.seed(124)
nvar <- ncol(df2)-1
bag <- randomForest(Bike_Injur~., data = df2, method = "class",
                    parms = list(split="gini"), mtry = nvar,na.action = na.roughfix)

```


```{r}
N<- c(700,708,0.5028409)
O<-c(609,932,0.3951979)

P<-rbind(N,O)

colnames(P)<-c("Non","Oui","Class.error")
rownames(P)<-c("Non","Oui")

kable(P,align = "c",caption = "Matrice de confusion appr") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)
```



En faisant un bagging on obtient une erreur OOB ( Out Of Bagg ) égale à 45.24%.

Nous allons comparer les erreurs entre les modèles bagging et random forest.

## Comparaison bagging  et Random forest

Nous allons içi comparer le modele random foret avec le modele bagging : 
```{r}
set.seed(124)
data.frame(tree=1:1500,
           rf=rf$err.rate[,1],
           bag=bag$err.rate[,1])%>%
  pivot_longer(cols = c(2,3),
           names_to="method",
           values_to="error")%>%
  ggplot()+aes(y=error,x=tree,
               color=method)+
  geom_line()+theme_minimal()

```

On peut voir qu'avec le modèle Random forest nous avons des taux d'erreur plus faible, ce qui peut suggérer que nos données sont classées généralement de la même manière dans la plupart du temps.

En comparant les erreurs des 2 modèles, pour 1500 arbres, on remarque que l'erreur correspondant à un Random Forest est plus faible que l'erreur du Bagging. 

De plus, les courbes ont la même allure mais la courbe du modèle le Bagging a un niveau d'ereur toujours plus élevé que le Random forest. On observe des "pics" significatifs à 500 et 1000 arbres.



# Boosting

En appliquant divers pénalités aux données d'apprentissage, on obtient les matrices de confusion suivantes : 

```{r}
set.seed(124)
df2$Bike_Injur<-as.factor(df2$Bike_Injur)
test_data$Bike_Injur<-as.factor(test_data$Bike_Injur)

boost<- ada(Bike_Injur~.,data=df2, type = "discrete", loss = "exponential", 
            control = rpart.control(cp = 0), iter = 200, nu = 1)

boostpen1 <- ada(Bike_Injur~.,data=df2, type = "discrete", loss = "exponential", 
            control = rpart.control(maxdepth = 1, cp = -1, minsplit = 0, xval = 0),
            iter = 200, nu = 0.1)

boostpen001 <- ada(Bike_Injur~.,data=df2, type = "discrete", loss = "exponential", 
            control = rpart.control(maxdepth = 1, cp = -1, minsplit = 0, xval = 0),
            iter = 200, nu = 0.01)
boostpen01 <- ada(Bike_Injur~.,data=df2, type = "discrete", loss = "exponential", 
            control = rpart.control(maxdepth = 1, cp = -1, minsplit = 0, xval = 0),
            iter = 200, nu = 0.001)
```

```{r}
v<- c(1387,21)
v1<-c(20,1521)

V11<-rbind(v,v1)

colnames(V11)<-c("Non","Oui")
rownames(V11)<-c("Non","Oui")

kable(V11,align = "c",caption = "Boosting p=0") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

o<- c(724,684)
o1<-c(477,164)

o11<-rbind(o,o1)

colnames(o11)<-c("Non","Oui")
rownames(o11)<-c("Non","Oui")

kable(o11,align = "c",caption = "Boosting p=0.1") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

oo<- c(448,960)
oo1<-c(246,1295)

oo11<-rbind(oo,oo1)

colnames(oo11)<-c("Non","Oui")
rownames(oo11)<-c("Non","Oui")

kable(oo11,align = "c",caption = "Boosting p=0.01") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

vv<- c(452,956)
vv1<-c(247,1294)

Vv11<-rbind(vv,vv1)

colnames(Vv11)<-c("Non","Oui")
rownames(Vv11)<-c("Non","Oui")

kable(Vv11,align = "c",caption = "Boosting p=0.001") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)
```




```{r} 
# ET CETTE PARTIE JE CONSEIL QU'ON L'ENLEVE ET ON GARDE LA PARTIE PREDICT
set.seed(124)
pred_b<- predict(boost,df2[,-4], type='prob')
plotb<-data.frame(pred_model1 = pred_b[,2], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+labs(title="courbe roc boosting")


```

```{r}
set.seed(124)
pred_b1<- predict(boostpen1,df2[,-4], type='prob')
plotb1<-data.frame(pred_model1 = pred_b1[,2], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+labs(title="courbe roc à 0,1  pénalisation")
```

```{r}
set.seed(124)
pred_b01<- predict(boostpen01,df2[,-4], type='prob')
plotb01<-data.frame(pred_model1 = pred_b01[,2], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+labs(title="courbe roc à 0,01 de pénalisation")
```


```{r}
set.seed(124)
pred_b001<- predict(boostpen001,df2[,-4], type='prob')
plotb001<-data.frame(pred_model1 = pred_b001[,2], obs = (pull(df2, Bike_Injur)=="Non")) %>%
  ggplot()+aes(d=obs,m=pred_model1)+geom_roc() + style_roc()+labs(title="courbe roc à 0,001 de pénalisation")
```

```{r}
set.seed(124)
library(gridExtra)
grid.arrange(plotb,plotb1,plotb01,plotb001, ncol=2, nrow = 2)
```



# Application à l'echantillon Test

## Arbre complet vs à arbre élagué.

### Arbre complet

```{r}
set.seed(124)
c1<-confusionMatrix(data = predict(tree, test_data[,-4], type='class'),reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")

x<-c(355,311)
x1<-c(352,456)

x2<-rbind(x,x1)
colnames(x2)<-c("Non","Oui")
rownames(x2)<-c("Non","Oui")

kable(x2,align = "c",caption = "Matrice de confusion test") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)


```

### Arbre élagué
```{r}
set.seed(124)
test_data$Bike_Injur<-as.factor(test_data$Bike_Injur)
c2<-confusionMatrix(data = predict(tree_pruned, test_data[,-4], type='class'),
                reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")

y<-c(353,299)
y1<-c(354,468)

y2<-rbind(y,y1)
colnames(y2)<-c("Non","Oui")
rownames(y2)<-c("Non","Oui")

kable(y2,align = "c",caption = "Matrice de confusion test") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)


```


Le taux de bonne prédiction de l'abre simplifié est plus élevé que le taux de prédiction bonne de l'arbre complet comme prévu, ceci est notamment dû au surrapprentissage sur les données d'entrainement.


## Modèle randomForest

Nous avons automatiser la recherche pour trouver  les meilleurs parametres pour un random forest. Aprés avoir trouvé les meilleurs paramètres nous allons lancer le modèle avec les paramètres obtenus.

```{r,include=F}
set.seed(124)
### modele de 50 100 200 noeux avec 1 4 8 23 variables qu'on regarde et foret de  10 50 100
nvar <- ncol(data)-1
system.time(
  rf.tune <- tune.randomForest(x = df2[complete.cases(df2),-4],
                               y = df2[complete.cases(df2),4],
                               nodesize = c(10,50,100,150), mtry = c(1,4,8,nvar), ntree = c(50,100,150,250))
)
rf
formattable (rf.tune$best.parameters)
formattable(rf.tune$best.model$confusion)

```

Le meilleur modéle possible est obtenu avec les paramètres suivants avec:
-  100 noeuds, 1 variables et 250 arbres.
- Et des class d'erreurs de 35% et 51%, ce qui est pas mal.


### Prédictions:

```{r}
set.seed(124)
df2$Bike_Injur<-as.factor(df2$Bike_Injur)
finalrf<-randomForest(Bike_Injur~., data = df2, method = "class",
                   parms = list(split = "gini"), na.action = na.roughfix,
                   keep.forest = TRUE, importance = TRUE,mtry=1,ntree=250,nodesize=100)
test_data$Bike_Injur<-as.factor(test_data$Bike_Injur)
c4<-confusionMatrix(data = predict(finalrf,newdata=test_data[,-4],type="class"),
                reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")

z<-c(267,160)
z1<-c(440,607)

z2<-rbind(z,z1)
colnames(z2)<-c("Non","Oui")
rownames(z2)<-c("Non","Oui")

kable(z2,align = "c",caption = "Matrice de confusion test") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

```

Jusqu'à présent le modèle Random Forest est le meilleure modèle prédictif notament par rapport à l'arbre de décision, ce qui est normale. L'arbre de décision n'est souvent pas le meilleur choix pour faire des prédictions.


# Le modèle Bootstrap

## Choix optimal

```{r,include=F}
set.seed(124)
tctrlboot <- tune.control(sampling = "bootstrap", nboot = 50)
system.time(treetune <- tune.rpart(Bike_Injur~., data = df2, tunecontrol = tctrlboot,na.action = na.roughfix,
                                 cp = seq(0.001,0.1,0.01)))
formattable ( treetune$best.parameter)
treetune$best.model$control


```

Le cp le plus optimal pour un bootstrap est de à 0.011 et à pour taux d'erreur de 37%.


```{r}
control1.max <- rpart.control(cp = 0.011, max.depth = 30, minbucket = 7, minsplit = 20,maxcompete = 4,maxsurrogate = 5,xval=10,maxdepth =30,nboot=50,sampling="bootstrap")
finaltree <- rpart(Bike_Injur~. , data = df2, control = control1.max,
              parms = list(split = "information"))
plot(finaltree,main="Arbre bootstrap" ,col="red")
prp(finaltree,main="Arbre bootstrap" ,col = "lightblue")

c5<-confusionMatrix(data = predict(finaltree,newdata=test_data[,-4],type="class"),
                reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")

zz<-c(352,265)
zz1<-c(355,502)

zz2<-rbind(zz,zz1)
colnames(zz2)<-c("Non","Oui")
rownames(zz2)<-c("Non","Oui")

kable(zz2,align = "c",caption = "Matrice de confusion test") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

```




```{r,include=F}

modeleb<- list(boosting_normal = boost,
               bossting_pen1 = boostpen1,
               bossting_pen01 = boostpen01,
               bossting_pen001= boostpen001
               
               )
library(MLmetrics)
mPred <- as.data.frame(lapply(modeleb, FUN = function(m){ predict(m, test_data[,-4], type='prob')[,2]}))

lapply(as.data.frame((mPred>0.5)*1), FUN = ConfusionMatrix, y_true = pull(test_data,Bike_Injur)=="Non")
```

## Matrice de confusion test des differents Boosting
```{r}
zzz<-c(330,437)
zzz1<-c(353,354)

zzz2<-rbind(zzz,zzz1)
colnames(zzz2)<-c("Non","Oui")
rownames(zzz2)<-c("Non","Oui")

kable(zzz2,align = "c",caption = "Boosting normal") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)


z4<-c(236,531)
z41<-c(344,363)

z42<-rbind(z4,z41)
colnames(z42)<-c("Non","Oui")
rownames(z42)<-c("Non","Oui")

kable(z42,align = "c",caption = "Boosting pen 1") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)


z5<-c(117,650)
z51<-c(201,506)

z52<-rbind(z5,z51)
colnames(z52)<-c("Non","Oui")
rownames(z52)<-c("Non","Oui")

kable(z52,align = "c",caption = "Boosting pen 0.1") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

zy<-c(114,653)
zy1<-c(119,508)

zy2<-rbind(zy,zy1)
colnames(zy2)<-c("Non","Oui")
rownames(zy2)<-c("Non","Oui")

kable(zy2,align = "c",caption = "Boosting pen 0.01") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)
```

```{r}
modelsPredictions <- lapply(modeleb, FUN = function(m){ predict(m, test_data[,-4], type='prob')[,1]})

mPredb <- as.data.frame(modelsPredictions)
```

```{r}
mPredb %>% mutate( obs = (pull(test_data, Bike_Injur)=="Non")*1) %>% 
  pivot_longer(cols = 1:4, names_to ="method", values_to = "pred") %>%
  ggplot()+aes(d=obs,m=pred,color=method)+geom_roc() + style_roc() +ggtitle("Courbe de ROC boosting")

```
 - On remarque que la meilleure courbe de ROC, est le boosting à 0.1 de pénalisation est  est sensiblement mieux comparée aux autres modèles.
 
 
### Matrice de confusion test du meilleure modèle Boosting:

```{r,include=F}
set.seed(124)
test_data$Bike_Injur<-as.factor(test_data$Bike_Injur)
confusionMatrix(data = predict(boostpen1,newdata=test_data[,-4],type="class"),
                reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")
```

```{r}
zyy<-c(344,236)
zyy1<-c(363,531)

zyy2<-rbind(zyy,zyy1)
colnames(zyy2)<-c("Non","Oui")
rownames(zyy2)<-c("Non","Oui")

kable(zyy2,align = "c",caption = "Matrice de confusion") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)
```




Un taux de précision de 0.581 pour le meilleure modèle de boosting parmis les 4 autres qu'on a effectué. 

```{r,include=F}
set.seed(124)
test_data$Bike_Injur<-as.factor(test_data$Bike_Injur)
confusionMatrix(data = predict(finalrf,newdata=test_data[,-4],type="class"),
                reference = pull(test_data,Bike_Injur), 
                mode = "everything", positive = "Non")
```

```{r}
vv<-c(265,160)
vv1<-c(442,607)

vv2<-rbind(vv,vv1)
colnames(vv2)<-c("Non","Oui")
rownames(vv2)<-c("Non","Oui")

kable(vv2,align = "c",caption = "Matrice de confusion") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)
```

# Scoring


```{r,echo=F,include=F}
data$Crash_Hour[data$Crash_Hour>= 8 & data$Crash_Hour<=19]<-"Jour"
data$Crash_Hour[data$Crash_Hour< 8 & data$Crash_Hour>19 ]<-"Nuit"
data$Crash_Hour[data$Crash_Hour<=1 ]<-"Nuit"



data$Bike_Age[data$Bike_Age<14 ]<-"Enfant"
data$Bike_Age[data$Bike_Age>= 14 & data$Bike_Age<= 30]<-"Jeune"
data$Bike_Age[data$Bike_Age> 30 & data$Bike_Age<= 70]<-"Adulte"


```


```{r,echo=F}
newdataqual<-data[,-c(1,2,4,12,13,15,16,17,20,21,22,23,24,25,27,28,30,34,35,38,40,41,44,45,46,47,50,51,52,54)]

```

&nbsp;

```{r,echo=F,include=F}
table(data$Bike_Race)
newdataqual$Bike_Race<-as.character(newdataqual$Bike_Race)
newdataqual$Bike_Race[newdataqual$Bike_Race=="Native American"]<-"Other"
newdataqual$Bike_Race[newdataqual$Bike_Race=="Asian"]<-"Other"
newdataqual$Bike_Race[newdataqual$Bike_Race=="Hispanic"]<-"Other"
newdataqual$Bike_Race[newdataqual$Bike_Race=="/Missing"]<-"Other"
table(newdataqual$Bike_Race)

table(data$Num_Lanes)
newdataqual$Num_Lanes<-as.character(newdataqual$Num_Lanes)
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="1 lane"]<-"Autre"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="2 lanes"]<-"2 voie"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="3 lanes"]<-"3_4_5 Voie"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="4 lanes"]<-"3_4_5 Voie"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="5 lanes"]<-"3_4_5 Voie"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="6 lanes"]<-"Autre"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="7 lanes"]<-"Autre"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="8 lanes"]<-"Autre"
newdataqual$Num_Lanes[newdataqual$Num_Lanes=="9 or more lanes"]<-"Autre"

table(newdataqual$Num_Lanes)
```


```{r,echo=F,include=F}
levels(newdataqual$Bike_Injur)

newdataqual$Bike_Injur<-as.character(newdataqual$Bike_Injur)

newdataqual$Bike_Injur[newdataqual$Bike_Injur=="A: Disabling Injury"]<-1
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="B: Evident Injury"]<-1
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="C: Possible Injury"]<-0
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="Injury"]<-1
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="K: Killed"]<-1
newdataqual$Bike_Injur[newdataqual$Bike_Injur=="O: No Injury"]<-0
table(newdataqual$Bike_Injur)

newdataqual$Drvr_Injur<-as.character(newdataqual$Drvr_Injur)
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="A: Disabling Injury"]<-"1"
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="B: Evident Injury"]<-"1"
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="C: Possible Injury"]<-"0"
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="Injury"]<-"1"
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="K: Killed"]<-"1"
newdataqual$Drvr_Injur[newdataqual$Drvr_Injur=="O: No Injury"]<-"0"
table(data$Drvr_Injur)



table(newdataqual$Bike_Pos)
newdataqual$Bike_Pos<-as.character(newdataqual$Bike_Pos)
newdataqual$Bike_Pos[newdataqual$Bike_Pos=="Bike Lane / Paved Shoulder"]<-"Other"
newdataqual$Bike_Pos[newdataqual$Bike_Pos=="Driveway / Alley"]<-"Other"
newdataqual$Bike_Pos[newdataqual$Bike_Pos=="Multi-use Path"]<-"Other"





levels(newdataqual$Light_Cond) 
newdataqual$Light_Cond<-as.character(newdataqual$Light_Cond)

newdataqual$Light_Cond[newdataqual$Light_Cond=="Dark -  Lighting"]<-"Tres_Sombre"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Dark - Lighted Roadway"]<-"Sombre"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Dark - Roadway Not Lighted"]<-"Tres_Sombre"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Dawn"]<-"Sombre"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Daylight"]<-"Clair"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Dusk"]<-"Sombre"
newdataqual$Light_Cond[newdataqual$Light_Cond=="Other"]<-"Sombre"
table(newdataqual$Light_Cond)


levels(newdataqual$Rd_Conditi)
newdataqual$Rd_Conditi<-as.character(newdataqual$Rd_Conditi)
newdataqual$Rd_Conditi[newdataqual$Rd_Conditi=="Water (Standing, Moving)"]<-"Wet"
newdataqual$Rd_Conditi[newdataqual$Rd_Conditi=="Sand, Mud, Dirt, Gravel"]<-"Other"
newdataqual$Rd_Conditi[newdataqual$Rd_Conditi=="Ice"]<-"Other"
newdataqual$Rd_Conditi[newdataqual$Rd_Conditi=="Snow"]<-"Other"
newdataqual$Rd_Conditi[newdataqual$Rd_Conditi=="Other"]<-"Wet"
table(newdataqual$Rd_Conditi)



levels(newdataqual$Drvr_Race)
newdataqual$Drvr_Race<-as.character(newdataqual$Drvr_Race)
newdataqual$Drvr_Race[newdataqual$Drvr_Race=="Native American"]<-"Other"
newdataqual$Drvr_Race[newdataqual$Drvr_Race=="Asian"]<-"Other"
newdataqual$Drvr_Race[newdataqual$Drvr_Race=="Hispanic"]<-"Other"

table(newdataqual$Drvr_Race)

colnames(newdataqual)
newdataqual$Workzone_I<-as.character(newdataqual$Workzone_I)
newdataqual$Workzone_I[newdataqual$Workzone_I=="No0"]<-"No"
table(newdataqual$Workzone_I)

levels(newdataqual$Developmen)
table(newdataqual$Developmen)
newdataqual$Developmen<-as.character(newdataqual$Developmen)
newdataqual$Developmen[newdataqual$Developmen=="Industrial"]<-"Farms_Pastures"
newdataqual$Developmen[newdataqual$Developmen=="Farms, Woods, Pastures"]<-"Farms_Pastures"


levels(newdataqual$Rd_Class)
table(newdataqual$Rd_Class)
newdataqual$Rd_Class<-as.character(newdataqual$Rd_Class)
newdataqual$Rd_Class[newdataqual$Rd_Class=="Interstate"]<-"US Route"
newdataqual$Rd_Class[newdataqual$Rd_Class=="Private Road, Driveway"]<-"Local Street"
newdataqual$Rd_Class[newdataqual$Rd_Class=="NC Route"]<-"US Route"
newdataqual$Rd_Class[newdataqual$Rd_Class=="State Secondary Route"]<-"US Route"
newdataqual$Rd_Class[newdataqual$Rd_Class=="Public Vehicular Area"]<-"US Route"




newdataqual$Bike_Pos<-as.character(newdataqual$Bike_Pos)
newdataqual$Bike_Pos[newdataqual$Bike_Pos=="Non-Roadway"]<-"Other"
newdataqual$Bike_Pos[newdataqual$Bike_Pos=="Sidewalk / Crosswalk / Driveway Crossing"]<-"Other"

newdataqual$Bike_Alc_D<-as.character(newdataqual$Bike_Alc_D)
newdataqual$Bike_Alc_D[newdataqual$Bike_Alc_D=="Missing"]<-"Yes"


newdataqual$Crash_Hour[newdataqual$Crash_Hour>= 8 & newdataqual$Crash_Hour<=19]<-"Jour"
newdataqual$Crash_Hour[newdataqual$Crash_Hour<8 & newdataqual$Crash_Hour>19 ]<-"Nuit"

table(newdataqual$Crash_Loc)
newdataqual$Crash_Loc<-as.character(newdataqual$Crash_Loc)
newdataqual$Crash_Loc[newdataqual$Crash_Loc=="Intersection-Related"]<-"Intersection"
newdataqual$Crash_Loc[newdataqual$Crash_Loc=="Location"]<-"Non-Intersection"
newdataqual$Crash_Loc[newdataqual$Crash_Loc=="Non-Roadway"]<-"Non-Intersection"

table(newdataqual$Crash_Loc)
```



```{r,echo=F}
newdataqual$Bike_Injur<-as.factor(newdataqual$Bike_Injur)
newdataqual$Bike_Pos<-as.factor(newdataqual$Bike_Pos)
newdataqual$Bike_Race<-as.factor(newdataqual$Bike_Race)
newdataqual$Bike_Pos<-as.factor(newdataqual$Bike_Pos)
newdataqual$Developmen<-as.factor(newdataqual$Developmen)
newdataqual$Drvr_Injur<-as.factor(newdataqual$Drvr_Injur)
newdataqual$Drvr_Race<-as.factor(newdataqual$Drvr_Race)
newdataqual$Rd_Class<-as.factor(newdataqual$Rd_Class)
newdataqual$Rd_Conditi<-as.factor(newdataqual$Rd_Conditi)
newdataqual$Workzone_I<-as.factor(newdataqual$Workzone_I)
newdataqual$Light_Cond<-as.factor(newdataqual$Light_Cond)
newdataqual$Rural_Urba<-as.factor(newdataqual$Rural_Urba)
newdataqual$Bike_Age<-as.factor(newdataqual$Bike_Age)
newdataqual$Crash_Hour<-as.factor(newdataqual$Crash_Hour)
```

```{r}
data2<-newdataqual[complete.cases(newdataqual),-c(1,9) ]

```

Comme toute bonne démarche de modélisation, la construction d'un bon **score** se fait par une succession d'étapes plus ou moins fondamentales en fonction des praticiens. 

Pour notre étude, nous commencerons par étudier la variable à expliquer,
vérifier la liaison entre les descripteurs et la variable à expliquer,
identifier les prédicteurs importants et les redondants afin de faire un modèle parcimonieux, estimer le modèle sur un échantillon d'apprentissage, valider le modèle sur un échantillon test et enfin construire les indicateurs de qualité du modèle ;

Nous comparerons plusieurs modèles et retiendrons le modèle le plus adéquat selon l'objectif de l'étude.


\

\

## Variable à expliquer

\
Revenons sur nos données initiales. La variable **Bike_Injur** est séparée en plusieurs modalités, comme suit : 

```{r}
bi<-data.frame(table(data$Bike_Injur))
bi1<-rbind(bi$Freq)
colnames(bi1)<-bi$Var1
```

```{r}
kable(bi1,"latex",align = "c") %>%
kable_styling(latex_options = c(" striped","hold_position"),
              position="center",full_width = F)

```

Nous allons affecter à ces modalités les valeurs 0 et 1. 

La valeur 1 : à celles qui concernent les blessures avérées et graves (Killed, Disabling Injury, Evident Injury et Injury)  et la valeur 0 à celles qui concerne l'absence, évidente ou non, de blessure (No Injury et Possible Injury). 

On obtient donc : 

```{r}
data2<-newdataqual[complete.cases(newdataqual),-c(1,9) ]

```

```{r}
re<-data.frame(table(data$Bike_Injur))
aaa<-c(0,1)
aaa1<-c(526+2199,291+2405+172+123)
C<-data.frame(rbind(aaa1))

row.names(C)<-c("Effectif")
colnames(C)<-c("0","1")

kable(C,align = "c") %>%
kable_styling(latex_options =c("striped","hold_position"),full_width = F) %>%
  add_header_above(c(" ", "Bike_Injur" = 2))
```

On souhaite déterminer la probabilité qu'un cycliste soit bléssé ou non compte tenu des paramêtres de son accident.

Pour cela, nous utiliserons une **_Régression logistique_**.

Nous allons effectuer une sélection de variables et ce pour plusieurs raisons.

D'abord parce que certaines des variables de notre base de données sont inutilisables en t'état et d'autre part parce qu'un modèle avec peu de variables sera plus facilement généralisable en terme de robustesse : *Principe du rasoir d'Occam*.


\

## Analyse exploratoire

Construisons une ACM afin d'essayer d'identifier les corrélations éventuelles entre les variables explicatives.

```{r}
library("FactoMineR")
library("factoextra")
res.pca <- MCA(data2, graph = FALSE)
```


```{r,fig.height=6}
library(gridExtra)
re<-fviz_pca_var(res.pca, col.var = "black",select.var = list(cos2 =0.1),gradient.cols = c("#3399FF","#663399"),labelsize = 3)

ree<-plot(res.pca, choix = "var",title="Rapport de correlation au carre", col.var = "black",xlim=c(0,0.75),ylim=c(0,0.6),label="none")

grid.arrange(re,ree,ncol=2)
```

Plusieurs variables semblent très corrélés, ce qui pourrait entrainer des problèmes de colinéarité lors de la régression.

\

\


## Echantillonnage : Apprentissage vs Test 

On garde les mêmes proportions que dans les modèles précédents, soit 70% attribuer à la construction du modèle et 30% attribuer au test.

```{r}
set.seed(111)

d = sort(sample(nrow(data2), nrow(data2) * 0.65))
# Echantillon d'apprentissage
appren <- data2[d, ]
# Echantillon de test
test <- data2[-d, ]

```

\

## Construction des modèles

&nbsp;

\begin{center}
Le modèle général s'écrit : 

\begin{large}
\[Y= \textbf{P}(Y=\frac{1}{\{X_j\}})+\epsilon=\pi(\{X_i\})+\epsilon = \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_jX_j}}{1+e^{\beta_0 + \sum_{j=1}^{p} \beta_jX_j}}+\epsilon\] 
\end{large}

avec 
\begin{eqnarray}
\epsilon = 1-\pi(X) &si& Y=1\\
\epsilon = -\pi(X) &si& Y=0
\end{eqnarray}

\end{center}

Y étant dans le cas de notre modèle, la variable à expliquer : *Bike_Injur*.\
$X_j$ un vecteur regroupant toutes les variables explicatives. \
$\beta_0$ la constante du modèle.\
$\beta_j$ un vecteur regroupant les coéfficients.

&nbsp;

Nous allons effectuer une sélection de variables et ce pour plusieurs raisons, la principale étant que :  un modèle avec peu de variables sera plus facilement généralisable en terme de robustesse *Principe du rasoir d'Occam*.

Le **premier modèle** que nous allons construire est un modèle naif. Il prend en compte toutes les variables, sans aucune spécification particulière : 
\begin{center}
$Bike\_Injur_i$ = $\beta_0$ + $\beta_1$ $Bike\_Age_i$ + $\beta_2$ $Bike\_Alc\_D_i$  + $\beta_3$ $Bike\_Dir_i$+ $\beta_4$ $Bike\_Pos_i$ + $\beta_5$ $Bike\_Race_i$  + $\beta_6$ $Bike\_Sex_i$ + $\beta_7$ $Crash\_Hour_i$ + $\beta_8$ $Crash\_Loc_i$ + $\beta_9$ $Developmen_i$  + $\beta_{10}$ $Drvr\_Alc\_D_i$ + $\beta_{11}$ $Drvr\_Injur_i$ + $\beta_{12}$ $Drvr\_Race_i$ + $\beta_{13}$ $Drvr\_Sex_i$ + $\beta_{14}$ $Hit\_Run_i$ + $\beta_{15}$ $Light\_Cond_i$ + $\beta_{16}$ $Num\_Lanes_i$ + $\beta_{17}$ $Rd\_Class_i$  + $\beta_{18}$ $Rd\_Conditi_i$ + $\beta_{19}$ $Region_i$ + $\beta_{20}$ $Rural\_Urba_i$ + $\beta_{21}$ $Workzone\_I_i$ + $\varepsilon_i$ 
\end{center}

Le **second modèle** à été obtenu en faisant une sélection automatique de variable, sur le critère d'Akaïke (AIC). Ce dernier s'écrit comme suit: $AIC= 2k-2\ln(L)$ ; où k est le nombre de paramètres à estimer du modèle et L est le maximum de la fonction de vraisemblance du modèle.
Si l'on considère un ensemble de modèles candidats, le modèle choisi est celui qui aura la plus faible valeur d'AIC. On obtient donc :
\begin{center}
$Bike\_Injur_i$ = $\beta_0$ +  $\beta_1$ $Bike\_Alc\_D_i$  + $\beta_2$ $Bike\_Dir_i$+ $\beta_3$ $Bike\_Pos_i$ + $\beta_4$ $Bike\_Race_i$ + $\beta_9$ $Developmen_i$  + $\beta_{5}$ $Drvr\_Alc\_D_i$ + $\beta_{6}$ $Rural\_Urba_i$ + $\beta_{7}$ $Workzone\_I_i$ + $\varepsilon_i$ 
\end{center}

Le **troisième modèle** est issue du second. On supprime toutes les variables non significatives du deuxième modèle:
\begin{center}
$Bike\_Injur_i$ = $\beta_0$ +  $\beta_1$ $Bike\_Alc\_D_i$  + $\beta_2$ $Bike\_Dir_i$+ $\beta_3$ $Bike\_Pos_i$ + $\beta_4$ $Bike\_Race_i$ + $\beta_{5}$ $Drvr\_Alc\_D_i$ + $\beta_{6}$ $Rural\_Urba_i$ + $\varepsilon_i$ 
\end{center}

Les résultats des régréssions  sont renseignées dans le tableau çi-dessous : 

```{r}
lm1<-glm(Bike_Injur~Bike_Age+ Bike_Alc_D+Bike_Dir+ Bike_Pos+ Bike_Race+ Bike_Sex+Crash_Hour+ Crash_Loc+Developmen+Drvr_Alc_D+ Drvr_Injur+ Drvr_Race+Drvr_Sex+ Rd_Conditi+Region  +Rural_Urba+Workzone_I, data=appren, family=binomial(link=logit)) 
```

```{r,include=FALSE}
require(MASS)
slm<-step(lm1, direction = "both")
```



```{r}
logit = function(formula, lien = "logit", data = NULL) {
    glm(formula, family = binomial(link = lien), data2)
}
```

```{r}
m.logit <- logit(Bike_Injur ~ Bike_Dir + Bike_Pos + Bike_Race + 
    Developmen + Drvr_Alc_D + Rural_Urba + Workzone_I, data = appren)

m.logit2 <- logit(Bike_Injur ~ Bike_Dir + Bike_Pos + Bike_Race + Drvr_Alc_D + Rural_Urba , data = appren)

```


```{r,warning=F,message=F,results='asis',header=F}
library(stargazer)
stargazer(m.logit,m.logit2,lm1,type="latex",header=F,font.size = "tiny",title="Résultats")
```

```{r}
library(GGally)
library(gridExtra)
```
&nbsp;



## Validation des modèles : Indicateurs de qualité et de robustesse



On exclu le modèle 3 car la plupart des coefficients ne sont pas significatifs.  

On s'intéressera donc exclusivement aux modèles 1 et 2.

```{r,warning=F,message=F,results='asis',header=F}
stargazer(m.logit,m.logit2,type="latex",header=F,font.size = "footnotesize",title="Résultats des modèles 2 et 3")
```

On construira tout d'abord un index plot pour détecter les valeurs aberrantes (en dehors des lignes) puis sur l'échantillon d'apprentissage et sur l'échantillon test, on calculera une matrice de confusion puis le taux d'erreur. Enfin, on évaluera l'air sous la courbe ROC.

## Résidus de déviances

Pour les régressions logistiques, on s'intéresse la plupart du temps aux résidus de déviance. Ils prennent généralement les valeurs qui oscillent entre -2 et 2. Construisons un index plot pour détecter les valeurs aberrantes.

```{r,fig.height=9}
par(mfrow = c(2, 1))
plot(rstudent(m.logit),main="Modèle 1", type = "p", cex = 0.5, ylab = "Résidus studentisés ", col = "black", ylim = c(-3, 3),xlab="")
abline(h = c(-2, 2), col = "red")

plot(rstudent(m.logit2),main="Modèle 2", type = "p", cex = 0.5, ylab = "Résidus studentisés ", col = "black", ylim = c(-3, 3),xlab="")
abline(h = c(-2, 2), col = "red")
```
Il semblerait qu'il n'y ait pas de valeurs aberrantes.



## Pertinence des modèles :

Nous allons tenter de valider maintenant sur l'échantillon test que nous avons précédemment défini.

Voici les étapes que nous allons suivre pour valider notre modèle
Sur l'échantillon d'apprentissage et sur l'échantillon test :
On calcule une matrice de confusion : et donc on mesure un taux d'erreur, puis on évalue l'air sous la courbe ROC.

&nbsp;

&nbsp;

\begin{center}
\textbf{Échantillon apprentissage}
\end{center}

```{r}
appren.p <- cbind(appren, predict(m.logit, newdata = appren, type = "link", 
    se = TRUE))
```


```{r}
appren.p <- within(appren.p, {
    PredictedProb <- plogis(fit, lower.tail = TRUE)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})
```

```{r}
appren.p <- cbind(appren.p, pred.bike_injur = factor(ifelse(appren.p$PredictedProb > 
    0.5, 1, 0)))
```

```{r}
appren.p1 <- cbind(appren, predict(m.logit2, newdata = appren, type = "link", 
    se = TRUE))

```



```{r}
appren.p1 <- within(appren.p1, {
    PredictedProb <- plogis(fit, lower.tail = TRUE)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

```

```{r}
appren.p1 <- cbind(appren.p1, pred.bike_injur = factor(ifelse(appren.p1$PredictedProb > 
    0.5, 1, 0)))
```

```{r}
# Matrice de confusion2
m.confusion1 <- as.matrix(table(appren.p1$pred.bike_injur, appren.p1$Bike_Injur))
```

```{r}
# Matrice de confusion
m.confusion <- as.matrix(table(appren.p$pred.bike_injur, appren.p$Bike_Injur))
vide<-c("","")

conf<-cbind(m.confusion ,vide,m.confusion1)
colnames(conf)<-c("0","1","","0","1")

kable(conf,align = "c",caption = "Matrice de confusion apprentissage") %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 16) %>%
add_header_above(c(" ", "Modèle 1" = 2," ","Modèle 2" = 2))
```
&nbsp;

\begin{center}
Qu'en est-il du taux d'erreur ?
\end{center}


```{r}
m.confusion <- unclass(m.confusion)
# Taux d'erreur
Tx_err <- function(y, ypred) {
    mc <- table(y, ypred)
    error <- (mc[1, 2] + mc[2, 1])/sum(mc)
    
}

m.confusion1 <- unclass(m.confusion1)
# Taux d'erreur
Tx_err1 <- function(y, ypred) {
    mc <- table(y, ypred)
    error <- (mc[1, 2] + mc[2, 1])/sum(mc)
    
}

```

```{r}
tx_a1<-Tx_err(appren.p$pred.bike_injur, appren.p$Bike_Injur)

tx_a2<-Tx_err1(appren.p1$pred.bike_injur, appren.p1$Bike_Injur)

```

```{r}
tx_a3<-cbind(tx_a1,tx_a2)

colnames(tx_a3)<-c("Modèle 1","Modèle 2")

kable(tx_a3,align = "c",caption = "Taux d'erreur") %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 16) 
```

&nbsp;


## Application à l'échantillon test




```{r}
test.p <- cbind(test, predict(m.logit, newdata = test, type = "response", se = TRUE))
test.p <- cbind(test.p, pred.bike_injur = factor(ifelse(test.p$fit > 0.5, 1, 0)))


m.confusiontest <- as.matrix(table(test.p$pred.bike_injur, test.p$Bike_Injur))


test.p1 <- cbind(test, predict(m.logit2, newdata = test, type = "response", se = TRUE))
test.p1 <- cbind(test.p1, pred.bike_injur = factor(ifelse(test.p1$fit > 0.5, 1, 0)))


m.confusiontest1 <- as.matrix(table(test.p1$pred.bike_injur, test.p$Bike_Injur))


conf1<-cbind(m.confusiontest ,vide,m.confusiontest1)
colnames(conf1)<-c("0","1","","0","1")

kable(conf1,align = "c",caption = "Matrice de confusion test") %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 16) %>%
add_header_above(c(" ", "Modèle 1" = 2," ","Modèle 2" = 2))

```

```{r}
m.confusiontest <- unclass(m.confusiontest)
# calcul du taux d'erreur sur l'échantillon test

```

\begin{center}
Qu'en est-il du taux d'erreur ?
\end{center}

```{r}
m.confusiontest1 <- unclass(m.confusiontest1)
# calcul du taux d'erreur sur l'échantillon test

tx3t<-Tx_err(test.p$pred.bike_injur, test.p$Bike_Injur)

tx3t2<-Tx_err(test.p1$pred.bike_injur, test.p1$Bike_Injur)

ttx3<-cbind(tx3t,tx3t2)

colnames(ttx3)<-c("Modèle 1","Modèle 2")


kable(ttx3,align = "c",caption = "Taux d'erreur test", escape = TRUE) %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 16) 
```

Le taux d'erreur est relativement le même pour les deux modèles. 

## Courbe ROC

```{r}
library(ROCR)
```

&nbsp;

\begin{center}
\huge{Modèle 1}
\end{center}

&nbsp;

```{r}
Pred = prediction(appren.p$PredictedProb, appren.p$Bike_Injur)
Perf = performance(Pred, "tpr", "fpr")
perf <- performance(Pred, "auc")

Predtest = prediction(test.p$fit, test.p$Bike_Injur)
Perftest = performance(Predtest, "tpr", "fpr")
perftest <- performance(Predtest, "auc")

par(mfrow = c(1, 2))
plot(Perf, colorize = TRUE, main = "ROC apprentissage - AUC= 0.8")
plot(Perftest, colorize = TRUE, main = "ROC Test - AUC =0.75 ")
```

\begin{center}
\textbf{Aire sous les courbes}
\end{center}

```{r}
airr<-data.frame(cbind(perf@y.values[[1]],perftest@y.values[[1]]))

colnames(airr)<-c("Modèle 1","Modèle 2")



```

&nbsp;

&nbsp;

\begin{center}
\huge{Modèle 2}
\end{center}

```{r}
Pred1 = prediction(appren.p1$PredictedProb, appren.p1$Bike_Injur)
Perf1 = performance(Pred1, "tpr", "fpr")
perf1 <- performance(Pred1, "auc")

Predtest1 = prediction(test.p1$fit, test.p1$Bike_Injur)
Perftest1 = performance(Predtest1, "tpr", "fpr")
perftest1 <- performance(Predtest1, "auc")

par(mfrow = c(1, 2))
plot(Perf1, colorize = TRUE, main = "ROC apprentissage - AUC= 0.8")
plot(Perftest1, colorize = TRUE, main = "ROC Test - AUC =0.75 ")


```

\

\

\begin{center}
\textbf{Aire sous les courbes}
\end{center}

```{r}

airr1<-data.frame(cbind(perf1@y.values[[1]],perftest1@y.values[[1]]))

colnames(airr1)<-c("Modèle 1","Modèle 2")

kable(airr,align = "c",caption = "Aire", escape = TRUE) %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 19) 
```

L'air sous les courbes est relativement le même lui aussi. On ne peut pas privilégié un modèle par rapport à l'autre.


\newpage 

# Choix du meilleure modèle:

## Récapitulatif Matrice de confusion test

```{r, include=F}
modelefinal<- list(ARBRE =tree,
               ARBRE_ÉLAGUÉ= tree_pruned,
               FORET_FINALE=finaltree,
               FORET_FINALEBIS=finalrf,
               BAGGING = bag,
               BOOSTING_PEN1= boostpen1
               
               )
library(MLmetrics)
library(MLmetrics)
mPredfinal <- as.data.frame(lapply(modelefinal, FUN = function(l){ predict(l, test_data[,-4], type='prob')[,1]}))

lapply(as.data.frame((mPredfinal>0.5)*1), FUN = ConfusionMatrix, y_true = pull(test_data, Bike_Injur)=="Non")
```

```{r}
kable(y2,align = "c",caption = "Matrice de confusion arbre") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

kable(x2,align = "c",caption = "Matrice de confusion arbre élagué") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

kable(zz2,align = "c",caption = "Matrice de confusion Forêt") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

kable(z2,align = "c",caption = "Matrice de confusion Forêt Bis") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

##
N1<- c(363,344)
O1<-c(307,460)

P1<-rbind(N1,O1)

colnames(P1)<-c("Non","Oui")
rownames(P1)<-c("Non","Oui")

kable(P1,align = "c",caption = "Matrice de confusion Boosting") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

##
kable(z52,align = "c",caption = "Matrice de confusion Boosting pen 0.1") %>%
kable_styling(latex_options=c("striped","bordered","hold_position"),full_width = F,font_size = 12)

kable(conf1,align = "c",caption = "Matrice de confusion Scoring") %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 13) %>%
add_header_above(c(" ", "Modèle 1" = 2," ","Modèle 2" = 2))
```

\newpage 

# Comparaison des taux d'erreur test

```{r}
ar<-(299+354)/(299+354+353+468)
arelag<-(311+352)/(311+352+355+456)
For<-(265+355)/(265+355+352+502)
Forbis<-(160+440)/(160+440+267+607)
Bag<-(344+307)/(344+307+363+460)
Boo<-(650+201)/(650+117+201+506)
Sc<-0.4035446

TABB<-rbind(ar,arelag,For,Forbis,Bag,Boo,Sc)

rownames(TABB)<-c("Arbre","Arbre élagué","Forêt","Forêt bis","Bagging","Boosting pen 0.1","Scoring")

colnames(TABB)<-c("Taux d'erreur test")


kable(TABB,align = "c",caption = "Comparaison des modèles") %>%
kable_styling(latex_options=c("striped","hold_position"),full_width = F,font_size = 16)
```


## Commentaires 

Les modèles que nous avons construit se valent, à l'exeption du Boosting pénalisé de 0,1 qui à un taux d'erreur test bien plus élevé que les autres. 
Le modèle avec le taux d'erreur le plus faible est le scoring. Cependant étant donné que ce modèle à été construit avec beaucoup moins de variables que les autres, toutes étant significatives, toute comparaison avec les autres modèles est à prendre avec des pincettes.

En tenant compte de ces divers considération, le modèle permettant de prédire le plus efficacement la variable **Bike_Injur** est le *Random Forest*.







